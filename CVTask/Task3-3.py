# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-uftXagnlTK_YdhnacNCvdgTqI_UlhYl
"""

import keras
import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
from keras import optimizers
from keras.datasets import cifar10
from keras.callbacks import LearningRateScheduler, TensorBoard
from keras.preprocessing.image import ImageDataGenerator

batch_size    = 128
epochs        = 100
iterations    = 391
num_classes   = 10

#defining model
model = tf.keras.models.Sequential([
    layers.Conv2D(6, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal', input_shape=(32,32,3)),
    layers.MaxPooling2D((2, 2), strides=(2, 2)),
    layers.Conv2D(16, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal'),
    layers.MaxPooling2D((2, 2), strides=(2, 2)),
    layers.Flatten(),
    layers.Dense(120, activation = 'relu', kernel_initializer='he_normal'),
    layers.Dense(84, activation = 'relu', kernel_initializer='he_normal'),
    layers.Dense(10, activation = 'softmax', kernel_initializer='he_normal'),
    
])
sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

# learning rate scheduler 
def scheduler(epoch):
    if epoch < 50:
        return 0.01
    if epoch < 75:
        return 0.005
    return 0.001

# load data
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

x_train = (x_train) / 255.0
x_test = (x_test ) / 255.0
        
    # build network

print(model.summary())
# set callback
tb_cb = TensorBoard(log_dir='./lenet_dp_da', histogram_freq=0)
change_lr = LearningRateScheduler(scheduler)
cbks = [change_lr,tb_cb]

print('Using real-time data augmentation.')

# data augmentation
datagen = ImageDataGenerator(
    zoom_range = 0.2,
    shear_range = 0.2
            )

datagen.fit(x_train)

    # start train 
model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),
                        steps_per_epoch=iterations,
                        epochs=epochs,
                        callbacks=cbks,
                        validation_data=(x_test, y_test))
